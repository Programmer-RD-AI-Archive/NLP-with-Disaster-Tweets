{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08dde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,torchvision\n",
    "import random\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "stemmer = PorterStemmer()\n",
    "PROJECT_NAME = 'kickstarter-NLP-V4'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1b568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentecne):\n",
    "    return nltk.word_tokenize(sentecne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d3062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '100']"
     ]
    }
   ],
   "source": [
    "tokenize('$100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a461fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54faec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'organ'"
     ]
    }
   ],
   "source": [
    "stem('organic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89eaa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,all_words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(all_words))\n",
    "    for idx,w in enumerate(all_words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db296873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1., 0., 1.])"
     ]
    }
   ],
   "source": [
    "bag_of_words(['hi'],['hi','how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e10880",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')\n",
    "X = data['']\n",
    "y = data['']\n",
    "words = []\n",
    "data = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434e2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e55d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this  # earthquake...       1  \n",
      "1              Forest fire near La Ronge Sask .  Canada       1  \n",
      "2     All residents asked to  ' shelter in place '  ...       1  \n",
      "3     13,000 people receive  # wildfires evacuation ...       1  \n",
      "4     Just got sent this photo from Ruby  # Alaska a...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609   @ Aria Ahrary  @ TheTawniest The out of contr...       1  \n",
      "7610  M1 . 94  [ 01 : 04 UTC ]  ? 5km S of Volcano H...       1  \n",
      "7611  Police investigating after an e - bike collide...       1  \n",
      "7612  The Latest :  More Homes Razed by Northern Cal...       1  \n",
      "\n",
      "[7613 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0edf9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be95140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id              keyword               location  \\\n",
      "234     334          annihilated                    NaN   \n",
      "2149   3084               deaths                    NaN   \n",
      "6621   9484            terrorism                    NaN   \n",
      "6001   8572              screams                    NaN   \n",
      "6288   8983                storm  Desert Storm?? |BCHS|   \n",
      "...     ...                  ...                    ...   \n",
      "6980  10011              twister             Everywhere   \n",
      "4221   5996            hazardous                    NaN   \n",
      "5467   7801           quarantine              Bucharest   \n",
      "1108   1601               bombed                    NaN   \n",
      "1363   1966  burning%20buildings          Selma2Oakland   \n",
      "\n",
      "                                                   text  target  \n",
      "234    @ TomcatArts thus explaining why you were all...       1  \n",
      "2149                   It is Time To Reduce Gun Deaths        1  \n",
      "6621   @ Kurt Schlichter  He is already done it by n...       1  \n",
      "6001   @ heyot6 Im not home .  I need to watch .   [...       0  \n",
      "6288  Happy birthday  @ lesley_mariiee  ?  I miss yo...       0  \n",
      "...                                                 ...     ...  \n",
      "6980  Just stop fucking saying a whole nother .  It ...       0  \n",
      "4221   # food scare  # offers to go  # Nestle India ...       1  \n",
      "5467   # Reddit updates  # content  # policy promise...       1  \n",
      "1108   @ oooureli  @ Abu_Baraa1 You mean like the to...       0  \n",
      "1363  Dudes will thoroughly express how stupid black...       1  \n",
      "\n",
      "[7613 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d59b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv').sample(frac=1)[:5000].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8c97965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id               keyword                    location  \\\n",
      "5776  8243               rioting                      Dublin   \n",
      "87     129              accident                    Maldives   \n",
      "3222  4624  emergency%20services                         USA   \n",
      "763   1104             blew%20up                         NaN   \n",
      "1370  1975          bush%20fires              Queen Creek AZ   \n",
      "...    ...                   ...                         ...   \n",
      "6083  8690              sinkhole                         NaN   \n",
      "5125  7310     nuclear%20reactor                       Pluto   \n",
      "5565  7940             rainstorm                 Fairfax, VA   \n",
      "5370  7662                 panic  Charlotte, NC | KÌ¦ln, NRW   \n",
      "3279  4705             epicentre                         CLT   \n",
      "\n",
      "                                                   text  target  \n",
      "5776  New doco tonight at 9pm Setanta Sports Ireland...       0  \n",
      "87    RT nAAYf :  First accident in years .  Turning...       1  \n",
      "3222   # Breaking  # News  -  Call for Tasmania ' s ...       1  \n",
      "763                I blew up snapchat for no reason  ?        0  \n",
      "1370  Ted Cruz fires back at Jeb  &  Bush :  We lose...       0  \n",
      "...                                                 ...     ...  \n",
      "6083             There is a sinkhole in Brooklyn  ?  !        1  \n",
      "5125   ' Nuclear reactor is like a woman .  You just...       0  \n",
      "5565  Tomorrow ' s evening commute receives a RED LI...       1  \n",
      "5370   @ elielcruz just watching the streams was bad...       1  \n",
      "3279  I need a spot w |  some drink specials .  I am...       0  \n",
      "\n",
      "[5000 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad5173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['target']\n",
    "words = []\n",
    "data = []\n",
    "labels = {}\n",
    "labels_r = {}\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6588779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in tqdm(y):\n",
    "    if label not in list(labels.keys()):\n",
    "        idx += 1\n",
    "        labels[label] = idx\n",
    "        labels_r[idx] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aebc570",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    new_X = []\n",
    "    for Xb in X_batch:\n",
    "        new_X.append(stem(Xb))\n",
    "    words.extend(new_X)\n",
    "    data.append([\n",
    "        new_X,\n",
    "        np.eye(labels[y_batch],len(labels))[labels[y_batch]-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bad5aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(words))\n",
    "np.random.shuffle(words)\n",
    "np.random.shuffle(data)\n",
    "np.random.shuffle(words)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bab6ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb150519",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence,tag in tqdm(data):\n",
    "    X.append(bag_of_words(sentence,words))\n",
    "    y.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9e7ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.125,shuffle=False)\n",
    "X_train = torch.from_numpy(np.array(X_train)).to(device).float()\n",
    "y_train = torch.from_numpy(np.array(y_train)).to(device).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).to(device).float()\n",
    "y_test = torch.from_numpy(np.array(y_test)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "000e346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "038769bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in tqdm(zip(preds,y)):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb1c843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(len(words),512)\n",
    "        self.linear2 = Linear(512,512)\n",
    "        self.linear3 = Linear(512,512)\n",
    "        self.linear4 = Linear(512,512)\n",
    "        self.linear5 = Linear(512,512)\n",
    "        self.output = Linear(512,len(labels))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        preds = self.activation(self.linear2(preds))\n",
    "        preds = self.activation(self.linear3(preds))\n",
    "        preds = self.activation(self.linear4(preds))\n",
    "        preds = self.activation(self.linear5(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "981abd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089413b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/kickstarter-NLP-V4\" target=\"_blank\">https://wandb.ai/ranuga-d/kickstarter-NLP-V4</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/kickstarter-NLP-V4/runs/250jsf6a\" target=\"_blank\">https://wandb.ai/ranuga-d/kickstarter-NLP-V4/runs/250jsf6a</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/NLP/NLP-with-Disaster-Tweets/wandb/run-20211017_212800-250jsf6a</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizers.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion)/2)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c538dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion)/2)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
